batch_size: 128
val_batch_size: 128
test_batch_size: 1024
train_data_size: 256
val_data_size: 64
test_data_size: 10000
optimizer: Adam
optimizer_kwargs:
  lr: 0.0005
  weight_decay: 1.0e-06
lr_scheduler: null
lr_scheduler_kwargs:
  milestones:
  - 80
  - 95
  gamma: 0.1
lr_scheduler_interval: epoch
lr_scheduler_monitor: val/reward
generate_default_data: false
shuffle_train_dataloader: false
dataloader_num_workers: 0
data_dir: data/
log_on_step: true
metrics: {}
baseline: shared
baseline_kwargs: {}
reward_scale: null
num_starts: 4
